{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-nonlinear-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfkajvL0mYcuaWv5aBxdAq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adnxs5kDc2pd"
      },
      "source": [
        "# 2. 非線形回帰モデル\n",
        "\n",
        "本書は、機械学習レポートの、非線形回帰モデルについてです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_jMHYWudCh3"
      },
      "source": [
        "# 1.1. 要点まとめ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUvNFVdHvJYP"
      },
      "source": [
        "単回帰の時の、回帰係数は、\n",
        "\n",
        "$$\n",
        "\\textbf{w} = ( X^TX )^{-1} \\cdot X^T \\cdot \\textbf{y} \\\\\n",
        "$$\n",
        "\n",
        "これが、非線形回帰モデルの場合は、以下となる。\n",
        "\n",
        "$$\n",
        "\\textbf{w} = ( \\Phi^T\\Phi )^{-1} \\cdot \\Phi^T \\cdot \\textbf{y} \\\\\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoTDeBStv8D6"
      },
      "source": [
        "例えば、 2 次の $ x $ の関数まで具体化して書くと、以下の通り。\n",
        "\n",
        "$$\n",
        "\\hat{w}\n",
        "=\n",
        "(\n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & x_{12}^2 \\\\\n",
        "1 & x_{21} & x_{22}^2\n",
        "\\end{pmatrix}^T\n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & x_{12}^2 \\\\\n",
        "1 & x_{21} & x_{22}^2\n",
        "\\end{pmatrix}\n",
        ")^{-1}\n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & x_{12}^2 \\\\\n",
        "1 & x_{21} & x_{22}^2\n",
        "\\end{pmatrix}^T\n",
        "\\begin{pmatrix}\n",
        "y_{1} \\\\\n",
        "y_{2}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "ここは、 $ X $ の部分が、 $ \\Phi $ 、つまり、個々の要素が $ \\Phi(x)$ で計算された行列式と理解。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPz3NtrYXIZn"
      },
      "source": [
        "単回帰では、 $ x $ であったところを、代わりに $ \\Phi(x) $ を用いる。 ( $ \\Phi(x) $ は $ x $ の任意の関数 )<br>\n",
        "ここで、 $ x $ が $ \\phi(x) $ に代わっても、 $ \\textbf{w} $ については線形のままである。<br>\n",
        "重み $ \\textbf{w} $ について線形とは、 liner-in-parameter という。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d85hmElCXrPH"
      },
      "source": [
        "基底関数 $ \\phi(x) $ の種類に、 Gauss 型基底関数がある。\n",
        "\n",
        "$$\n",
        "\\phi_j(x) = exp{-\\frac{(x - \\mu_j)^2}{2h_j}} \\\\\n",
        "=\n",
        "exp{-\\frac{(x - \\mu_j)^2}{\\sigma~2}}\n",
        "$$\n",
        "\n",
        "ある点 $ \\mu_1, \\mu_2 $ と、 $ x_i $ の距離を、\n",
        "$ 2h_j, \\sigma^2 $ の広がりでコントロールしている。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LESNYELfaJB_"
      },
      "source": [
        "\"非線形関数の計画行列\" の $ n \\times k $ の行列を書くと、\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmMR_mfwoJb6"
      },
      "source": [
        "単回帰では、\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{y}} = X\\boldsymbol{w}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & x_{12} & \\dots & x_{1m} \\\\\n",
        "1 & x_{21} & x_{22} & \\dots & x_{2m} \\\\\n",
        "\\dots \\\\\n",
        "1 & x_{n1} & x_{n2} & \\dots & x_{nm}\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "\\dots \\\\\n",
        "w_{m}\n",
        "\\end{pmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3eV4_Yzp4OD"
      },
      "source": [
        "今回の多項式回帰では、\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{y}} = \\boldsymbol{\\phi}(\\boldsymbol{x})\\boldsymbol{w}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & \\phi_1(x_{11}) & \\phi_2(x_{12}) & \\dots & \\phi_m(x_{1m}) \\\\\n",
        "1 & \\phi_1(x_{21}) & \\phi_2(x_{22}) & \\dots & \\phi_m(x_{2m}) \\\\\n",
        "\\dots \\\\\n",
        "1 & \\phi_1(x_{n1}) & \\phi_2(x_{n2}) & \\dots & \\phi_m(x_{nm})\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "\\dots \\\\\n",
        "w_{m}\n",
        "\\end{pmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoKzJjy2b0Pz"
      },
      "source": [
        "MSE を最小する $ \\textbf{w} $ は、単回帰と同様に、\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NXM-LNtb9Y-"
      },
      "source": [
        "$$\n",
        "\\hat{\\textbf{w}} = (X^T X)^(-1) X^T \\textbf{y} \\\\\n",
        "\\to\n",
        "\\hat{\\textbf{w}} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\textbf{y} \\\\\n",
        "\\therefore\n",
        "\\hat{\\textbf{y}} = \\Phi_{*} \\cdot \\hat{\\textbf{w}}\n",
        "=\n",
        "\\Phi_{*} \\cdot (\\Phi^T \\Phi)^{-1} \\Phi^T \\textbf{y} \\\\\n",
        "$$\n",
        "\n",
        "と、予測値が得られる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2sq9SraeAiL"
      },
      "source": [
        "過学習の対策は、以下の 3 つ。\n",
        "\n",
        "1. 学習データの数を増やす\n",
        "2. 不要な基底関数(変数)の削除<br>Cross Validation などて選択する。\n",
        "3. 正則化法の利用<br>\n",
        "モデルの複雑さで値が大きくなる罰則項を追加する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPt7BqvffI4i"
      },
      "source": [
        "正則化法では、 $ J(\\textbf{w} ) $ を MSE とすして、以下の目的関数に罰則項を追加すること。\n",
        "\n",
        "$$\n",
        "E(\\textbf{w}) = J(\\textbf{w}) + \\lambda \\cdot \\textbf{w}^T \\textbf{w}\n",
        "$$\n",
        "\n",
        "$ \\textbf{w} $ が大きくなると、罰則項が大きくなるので、目的関数の最小化をする中で、\n",
        "MSE を最小化しつつ、 $ \\textbf{w} $ も最小化する。\n",
        "\n",
        "- 縮小推定\n",
        "  - Ridge 推定量<br>\n",
        "  L2 ノルムを使用。パラメータを 0 に近づけるように推定\n",
        "\n",
        "- スパース推定\n",
        "  - Lasso 推定量<br>\n",
        "  L1 ノルムを使用。いくつかのパラメータを正確に 0 に推定。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9KWr7UkhmWi"
      },
      "source": [
        "解きたいのは、 $ min MSE s.t. R(\\textbf{w}) \\le r $ 。不等式条件のある最適化問題。<br>\n",
        "KKT 条件を使うと、<br>\n",
        "$$\n",
        "min MSE + \\lambda \\cdot R(\\textbf{w})\n",
        "$$\n",
        "\n",
        "スライド ( page.41 ) のグレーの範囲は、 $ R(\\textbf{w}) $ の範囲のこと。<br>\n",
        "右上の楕円は、 MSE のこと。最初は黒丸であるが、そこを広げて、<br>\n",
        "( 等高線の様に楕円が広がっていって、)<br>\n",
        "グレーの範囲と接したところを最適解とする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVSZQxuvjye3"
      },
      "source": [
        "正則化を行ったグラフの方が滑らかに近似し、正則化していないで、基底関数が多いグラフと比べてオーバーフィッティングしていないことが分かる。\n",
        "( スライド page.42 )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-nkaC_ok12S"
      },
      "source": [
        "正則化法のパラメータ $ \\gamma ( \\gamma \\gt 0 ) $ はハイパーパラメータ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrZJzNXwliaq"
      },
      "source": [
        "汎化性能、バイアス・バリアンス分解の内容に入る。 ( 講義: 59:23 )\n",
        "\n",
        "- バイアス・バリアンス分解<br>\n",
        "[バイアス-バリアンス分解：機械学習の性能評価 - HELLO CYBERNETICS](https://www.hellocybernetics.tech/entry/2017/01/24/100415)<br>\n",
        "スライド page. 45 のリンクの内容を確認した。バイアスとバリアンスはトレードオフの関係にあり、バランスの取れた正則化パラメータの調整が必要と理解した。 <br>\n",
        "  - バイアス: 未学習に対する指標<br>\n",
        "  正則化項のパラメータを大きくすると、上昇。\n",
        "  > モデルが単純であるあまりに学習が上手くいかない度合い\n",
        "  - バリアンス: 過学習に対する指標<br>\n",
        "  正則化項のパラメータを大きくすると、低下。\n",
        "  > 訓練データに依存し過ぎることで新しいデータへの予測が悪化する度合い\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwP0KMXQwpU8"
      },
      "source": [
        "- NOTE: 参考: [Deep Double Descent](https://openai.com/blog/deep-double-descent/)<br>\n",
        "ディープラーニングの場合は、学習を続けると汎化性能も上がり始める。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxFusqFGw_bD"
      },
      "source": [
        "学習用とテスト用で、データを分割する方法は、以下の 3つ。\n",
        "\n",
        "1. ホールドアウト\n",
        "2. クロスバリデーション(交差検証)<br>\n",
        "チューニングパラメータは固定。モデルを変えて、 CV値(精度の平均) が良いモデルを試行する。\n",
        "\n",
        "講義中の質問( 講義: 1:10:53 ) より、学習誤差と検証誤差は同じもの(MSEならば、MSE)を使うのが望ましいとのこと。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYdmahUryQZI"
      },
      "source": [
        "グリッドサーチ。( 講義: 1:15:04 )\n",
        "\n",
        "- NOTE: [Hyperparameter optimization - Wikipedia](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization) などがある。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS32uLpc3MZX"
      },
      "source": [
        "- NOTE: [赤池情報量規準 - Wikipedia](https://ja.wikipedia.org/wiki/%E8%B5%A4%E6%B1%A0%E6%83%85%E5%A0%B1%E9%87%8F%E8%A6%8F%E6%BA%96)\n",
        "<br>\n",
        "講義中、モデルの評価をする上で紹介された手法。\n",
        "AIC: モデルと特徴量の数の、妥当性を測るもの。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRsH3xoqdErY"
      },
      "source": [
        "# 1.2. 実装演習\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-ol8NcYdGms"
      },
      "source": [
        "## np_regression.ipynb\n",
        "\n",
        "`np_regression.ipynb` の \"多項式回帰\" について、実装演習を行った。<br>\n",
        "自身の実行環境で、実行を確認したキャプチャは、 [1. 線形回帰モデル のレポート](https://render.githubusercontent.com/view/ipynb?color_mode=auto&commit=ac163a3a101e84738bcd27c9651901788aad2836&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f796f7368696e616b2f73747564792d61692d73746167652d322f616331363361336131303165383437333862636432376339363531393031373838616164323833362f315f6c696e6561725f72656772657373696f6e2e6970796e62&nwo=yoshinak%2Fstudy-ai-stage-2&path=1_linear_regression.ipynb&repository_id=427871847&repository_type=Repository#%E3%82%AD%E3%83%A3%E3%83%97%E3%83%81%E3%83%A3) の通り。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK5oR_pQP77q"
      },
      "source": [
        "##### 多項式回帰\n",
        "\n",
        "学習の( コードセル[8]の下 )、数式について、確認した。\n",
        "\n",
        "$ y(x) = \\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{\\phi(x)} $ について、\n",
        "\n",
        "$ w^T $ は列 ベクトル。<br>\n",
        "$ \\phi(x) $ は行 ベクトル。\n",
        "\n",
        "よって、\n",
        "\n",
        "$$\n",
        "\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{\\phi(x)}\n",
        "=\n",
        "w_0 + w_1x + w_2x^2 + \\dots + w_dx^d\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odjJO3OgRcXX"
      },
      "source": [
        "講義の中では、 $ \\Phi_1, \\Phi_2 $ の例だった。\n",
        "これを講義の、少し前の説明での 9 乗までの $ \\Phi_9 $ に倣って、書いてみると、\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnllA53WRnZP"
      },
      "source": [
        "$$\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "1 & x_{11} & x_{12}^2 \\\\\n",
        "1 & x_{21} & x_{22}^2\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "コードセル[9] の`polynomial_features()` の結果から、上記の様に理解する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaUjHtGQdK57"
      },
      "source": [
        "## skl_nonlinear regression.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zukz8W6Zd0qm"
      },
      "source": [
        "### キャプチャ\n",
        "\n",
        "自身の環境において、最終コードセル[52]までの実行を確認した。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1pS0nah3TNE"
      },
      "source": [
        "![capture-skl_nonlinear regression.ipynb-cell-52.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlPQGpLAgsSS"
      },
      "source": [
        "#### 内容\n",
        "\n",
        "実装演習の際、調べた内容についてのノートを記録する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCxXMpJh3kOG"
      },
      "source": [
        "##### LinearRegression\n",
        "\n",
        "コードセル[6] において、以下のコードを追加し、モデルのパラメータと $ X $ のランクを確認した。\n",
        "\n",
        "```\n",
        "params = clf.get_params()\n",
        "print(\"params={}\".format(params))\n",
        "...\n",
        "print(\"Rank of matrix X: clf.rank_={}\".format(clf.rank_))\n",
        "```\n",
        "\n",
        "```\n",
        "params={'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n",
        "(100, 1)\n",
        "Rank of matrix X: clf.rank_=1\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-txkkKg5UgH"
      },
      "source": [
        "##### KernelRidge\n",
        "\n",
        "ドキュメントを確認。 L2 正則化とカーネル回帰を組合せたものと理解した。\n",
        "\n",
        "- [sklearn.kernel_ridge.KernelRidge — scikit-learn 1.0.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html)\n",
        "\n",
        "また、以下より、過学習になりやすいカーネル回帰の汎化性能を高めるために、 L2 正則化を行うことを確認した。\n",
        "\n",
        "- [カーネル法入門｜カーネル回帰とカーネルリッジ回帰 | マサムネの部屋](https://masamunetogetoge.com/kernelpart1)<br>\n",
        "( 前半部、表示が崩れているが、後半に説明がある )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t8DnJBZ5dgm"
      },
      "source": [
        "##### Ridge\n",
        "\n",
        "`score` の計算方法にについて、確認した。\n",
        "\n",
        "- [sklearn.linear_model.LinearRegression — scikit-learn 1.0.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score)<br>\n",
        "決定係数のこと。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b16NMVB-5fWC"
      },
      "source": [
        "##### PolynomialFeatures\n",
        "\n",
        "講義の中では 4 次がちょうどよい話。ここで得られたグラフにおいても、以下の様に 5 以降を表示しなくても、4 次で充分近似するグラフを得た。\n",
        "\n",
        "```\n",
        "# deg = [1,2,3,4,5,6,7,8,9,10]\n",
        "deg = [1,2,3,4]\n",
        "for d in deg:\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXhwqLEZ5iCr"
      },
      "source": [
        "##### Lasso\n",
        "\n",
        "講義の中の L1 ノルムを使用した正則化。\n",
        "今回の例では、結果のグラフは直線であり、採用にあたって効果はなかったものと理解した。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HX5ifWn64fr"
      },
      "source": [
        "##### SVR-rbf\n",
        "\n",
        "サポートベクトルマシンを使用した、サポートベクトル回帰。<br>\n",
        "ドキュメントを確認し、通常、 `kernel='rbf'` の選択が近似しやすいと理解した。\n",
        "\n",
        "- [Support Vector Regression (SVR) using linear and non-linear kernels — scikit-learn 1.0.1 documentation](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PecUol_I7wUk"
      },
      "source": [
        "##### keras\n",
        "\n",
        "グラフのタイトルより、 `NonLiner Regressions via DL by ReLU` 。\n",
        "コードでは、以下でモデルを作成していると理解。\n",
        "\n",
        "```\n",
        "estimator = KerasRegressor(build_fn=relu_reg_model, epochs=100, batch_size=5, verbose=1)\n",
        "```\n",
        "\n",
        "グラフより精度の高い結果を得た。\n",
        "\n",
        "- NOTE: 実行時、 2 GiB 超の領域が、 Google Drive に必要。\n"
      ]
    }
  ]
}